# Multivariate outlier detection
This approach to detecting outliers is based on the distribution of the observed robust mahalanobis distances in relation to the expected theoretical distribution. Outlier points are identified as those that cause the distribution to deviate from the theoretical distribution (i.e., a chi-squared distribution) as follows: a linear model is fit to the ordered robust distances against the quantiles of a chi-squared distribution. Subsequently, outliers are identified by iteratively removing the point corresponding to the largest robust distance until the coefficient of the determination for the linear model passes a threshold.
